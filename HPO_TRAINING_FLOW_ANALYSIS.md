# HPO â†’ Training AkÄ±ÅŸ Analizi ve Kritik Bulgular

**Tarih:** 2025-11-24  
**Durum:** ğŸ”´ **Kritik farklÄ±lÄ±klar tespit edildi**

---

## ğŸ“‹ AkÄ±ÅŸ Ã–zeti

### HPO AkÄ±ÅŸÄ± (`optuna_hpo_with_feature_flags.py`):
1. **Data Fetching:** `fetch_prices(engine, symbol)` - **Cache BYPASS, direkt DB'den**
2. **Split Generation:** `generate_walkforward_splits(total_days, horizon, n_splits=4)`
3. **Her Split Ä°Ã§in:**
   - Model eÄŸitimi: `ml.train_enhanced_models(sym, train_df)`
   - `raw_r2` deÄŸerleri hesaplanÄ±yor (XGB, LGB, CatBoost iÃ§in)
   - Walk-forward prediction: `ml.predict_enhanced(sym, cur)`
   - `predict_enhanced` iÃ§inde:
     - Model'lerden prediction alÄ±nÄ±yor
     - `historical_r2` = model'lerin `raw_r2` deÄŸerleri
     - `smart_ensemble(historical_r2=historical_r2, ...)` â†’ `ensemble_prediction`
   - `pred_return = pred_price / last_close - 1.0`
   - DirHit hesaplama: `dirhit(y_true, preds, thr=0.005)`
4. **Ortalama:** TÃ¼m split'lerin DirHit'leri ortalanÄ±yor

### Training AkÄ±ÅŸÄ± (`continuous_hpo_training_pipeline.py`):
1. **Data Fetching:** `det.get_stock_data(symbol, days=0)` - **Cache kullanÄ±yor olabilir**
2. **Split Generation:** `generate_walkforward_splits(total_days, horizon, n_splits=4)` - **AynÄ± fonksiyon**
3. **Her Split Ä°Ã§in:**
   - Model eÄŸitimi: `ml_eval.train_enhanced_models(symbol, train_df_split)`
   - `raw_r2` deÄŸerleri hesaplanÄ±yor (XGB, LGB, CatBoost iÃ§in)
   - Walk-forward prediction: `ml_eval.predict_enhanced(symbol, cur)`
   - `predict_enhanced` iÃ§inde:
     - Model'lerden prediction alÄ±nÄ±yor
     - `historical_r2` = model'lerin `raw_r2` deÄŸerleri
     - `smart_ensemble(historical_r2=historical_r2, ...)` â†’ `ensemble_prediction`
   - `pred_return = pred_price / last_close - 1.0`
   - DirHit hesaplama: `_dirhit(y_true_split, preds, thr=0.005)`
4. **Ortalama:** TÃ¼m split'lerin DirHit'leri ortalanÄ±yor

---

## ğŸ”´ KRÄ°TÄ°K BULGULAR

### 1. **Data Source FarklÄ±lÄ±ÄŸÄ±** ğŸ”´ **Ã‡OK KRÄ°TÄ°K**

**HPO:**
```python
df = fetch_prices(engine, sym)  # Cache BYPASS, direkt DB'den
# âš¡ CRITICAL FIX: Skip cache for HPO to ensure fresh data from DB
```

**Training:**
```python
df = det.get_stock_data(symbol, days=0)  # Cache KULLANIYOR!
# pattern_detector.py:387-390
cached = self._df_cache.get(symbol)
if cached and (now_ts - float(cached.get('ts', 0))) < float(self.data_cache_ttl):
    return df_cached  # Cache'den dÃ¶nÃ¼yor!
```

**Etki:**
- HPO cache'i bypass ediyor, training cache kullanÄ±yor
- Cache stale olabilir veya farklÄ± veri iÃ§erebilir
- Bu farklÄ± `total_days` deÄŸerlerine yol aÃ§abilir
- FarklÄ± `total_days` â†’ farklÄ± split'ler â†’ farklÄ± train/test data
- **SONUÃ‡:** FarklÄ± veri â†’ farklÄ± model eÄŸitimi â†’ farklÄ± `raw_r2` â†’ farklÄ± ensemble aÄŸÄ±rlÄ±klarÄ± â†’ farklÄ± predictions â†’ farklÄ± DirHit

**Ã‡Ã¶zÃ¼m:**
- Training'de de cache'i bypass etmeli (HPO ile tutarlÄ±lÄ±k iÃ§in)
- Veya `get_stock_data`'ya cache bypass parametresi ekle

---

### 2. **historical_r2 FarklÄ±lÄ±ÄŸÄ±** ğŸ”´ **Ã‡OK KRÄ°TÄ°K**

**Sorun:**
- `historical_r2` deÄŸerleri model eÄŸitimi sÄ±rasÄ±nda hesaplanÄ±yor (`raw_r2`)
- Bu deÄŸerler `smart_ensemble`'Ä±n aÄŸÄ±rlÄ±klarÄ±nÄ± etkiliyor
- FarklÄ± train data â†’ farklÄ± `raw_r2` â†’ farklÄ± ensemble aÄŸÄ±rlÄ±klarÄ± â†’ farklÄ± `ensemble_prediction`

**Kod:**
```python
# enhanced_ml_system.py:4893-4908
historical_r2 = []
for info in model_predictions.values():
    r2_val = info.get('raw_r2')  # Model eÄŸitimi sÄ±rasÄ±nda hesaplanan RÂ²
    if r2_val is not None:
        historical_r2.append(float(r2_val))
    else:
        # Fallback: confidence'den reverse-engineer
        conf = float(info.get('confidence', 0.5))
        approx_r2 = max(-0.5, min(0.8, (conf - 0.3) / 0.65 * 0.8))
        historical_r2.append(approx_r2)

# smart_ensemble bu historical_r2'yi kullanarak aÄŸÄ±rlÄ±klarÄ± hesaplÄ±yor
ensemble_pred, final_weights = smart_ensemble(
    predictions=np.array(predictions_list),
    historical_r2=historical_r2,  # âš ï¸ Bu deÄŸerler farklÄ± olabilir!
    ...
)
```

**Etki:**
- HPO'da train_df ile eÄŸitilen model'in `raw_r2` deÄŸerleri
- Training'de train_df_split ile eÄŸitilen model'in `raw_r2` deÄŸerleri
- EÄŸer split'ler farklÄ±ysa veya data farklÄ±ysa, `raw_r2` farklÄ± olur
- Bu da `smart_ensemble`'Ä±n farklÄ± aÄŸÄ±rlÄ±klar kullanmasÄ±na yol aÃ§ar
- SonuÃ§: FarklÄ± `ensemble_prediction` â†’ farklÄ± `pred_return` â†’ farklÄ± DirHit

**Ã–rnek Senaryo (AHGAZ):**
1. HPO Split 1: train_df (448 gÃ¼n) â†’ XGB raw_r2=0.15, LGB raw_r2=0.12, Cat raw_r2=0.10
2. Training Split 1: train_df_split (448 gÃ¼n ama farklÄ± data?) â†’ XGB raw_r2=0.08, LGB raw_r2=0.05, Cat raw_r2=0.03
3. HPO'da smart_ensemble aÄŸÄ±rlÄ±klarÄ±: [0.4, 0.35, 0.25] (XGB daha yÃ¼ksek)
4. Training'de smart_ensemble aÄŸÄ±rlÄ±klarÄ±: [0.33, 0.33, 0.34] (daha eÅŸit)
5. FarklÄ± aÄŸÄ±rlÄ±klar â†’ farklÄ± ensemble_prediction â†’ farklÄ± DirHit

---

### 3. **Seed UyumsuzluÄŸu** âœ… **DÃœZELTÄ°LDÄ°**

**Ã–nceki Sorun:**
- HPO: `ml.base_seeds = [42 + trial.number]` (trial 1262 â†’ seed 1304)
- Training: `ml_eval.base_seeds = [42 + eval_seed]` (eval_seed=42 fallback)

**DÃ¼zeltme:**
- Training'de `best_trial_number` kullanÄ±lÄ±yor
- `eval_seed = best_trial_number if best_trial_number is not None else 42`
- `ml_eval.base_seeds = [42 + eval_seed]`

**Durum:** âœ… DÃ¼zeltildi, ama doÄŸrulanmalÄ±

---

### 4. **Split TutarlÄ±lÄ±ÄŸÄ±** âš ï¸ **KONTROL EDÄ°LMELÄ°**

**Sorun:**
- HPO ve training aynÄ± `generate_walkforward_splits` fonksiyonunu kullanÄ±yor
- Ama `total_days` farklÄ± olabilir (data source farklÄ±lÄ±ÄŸÄ± nedeniyle)
- FarklÄ± `total_days` â†’ farklÄ± split'ler â†’ farklÄ± train/test data

**Kontrol:**
- HPO'da: `total_days = len(df)` (fetch_prices'den gelen)
- Training'de: `total_days = len(df)` (get_stock_data'den gelen)
- Bu deÄŸerler aynÄ± mÄ±?

---

### 5. **Feature Flags Uygulama** âœ… **DOÄRU GÃ–RÃœNÃœYOR**

**Kontrol:**
- Best params'tan feature flags set ediliyor
- Smart ensemble params set ediliyor
- Environment variables doÄŸru set ediliyor

**Durum:** âœ… DoÄŸru gÃ¶rÃ¼nÃ¼yor, ama doÄŸrulanmalÄ±

---

## ğŸ¯ Ã–NCELÄ°KLÄ° SORUNLAR

### 1. **Data Source TutarlÄ±lÄ±ÄŸÄ±** ğŸ”´ **KRÄ°TÄ°K**
- **Sorun:** HPO cache bypass, training cache kullanÄ±yor olabilir
- **Etki:** FarklÄ± veri â†’ farklÄ± split'ler â†’ farklÄ± sonuÃ§lar
- **Ã‡Ã¶zÃ¼m:** Training'de de cache'i bypass et veya HPO'da da cache kullan

### 2. **historical_r2 FarklÄ±lÄ±ÄŸÄ±** ğŸ”´ **Ã‡OK KRÄ°TÄ°K**
- **Sorun:** `raw_r2` deÄŸerleri farklÄ± train data ile farklÄ± hesaplanÄ±yor
- **Etki:** FarklÄ± ensemble aÄŸÄ±rlÄ±klarÄ± â†’ farklÄ± predictions â†’ farklÄ± DirHit
- **Ã‡Ã¶zÃ¼m:** 
  - HPO'da hesaplanan `raw_r2` deÄŸerlerini best_params'a kaydet
  - Training'de bu kaydedilen `raw_r2` deÄŸerlerini kullan (model eÄŸitimi sÄ±rasÄ±nda deÄŸil, prediction sÄ±rasÄ±nda)

### 3. **Split TutarlÄ±lÄ±ÄŸÄ± DoÄŸrulama** ğŸŸ¡ **ORTA**
- **Sorun:** Split'ler aynÄ± mÄ±?
- **Etki:** FarklÄ± split'ler â†’ farklÄ± train/test data â†’ farklÄ± sonuÃ§lar
- **Ã‡Ã¶zÃ¼m:** HPO ve training'de aynÄ± split'leri kullandÄ±ÄŸÄ±nÄ± doÄŸrula (log ekle)

---

## ğŸ” DETAYLI Ä°NCELEME GEREKLÄ°

### AHGAZ Ã–rneÄŸi Ä°Ã§in:
1. **HPO'da kullanÄ±lan data:**
   - `fetch_prices` â†’ kaÃ§ gÃ¼n? Hangi tarih aralÄ±ÄŸÄ±?
   - Split'ler: train_end_idx, test_end_idx deÄŸerleri?

2. **Training'de kullanÄ±lan data:**
   - `get_stock_data` â†’ kaÃ§ gÃ¼n? Hangi tarih aralÄ±ÄŸÄ±?
   - Split'ler: train_end_idx, test_end_idx deÄŸerleri?

3. **HPO'da hesaplanan raw_r2 deÄŸerleri:**
   - Trial 1262, Split 1: XGB raw_r2=?, LGB raw_r2=?, Cat raw_r2=?
   - Bu deÄŸerler best_params'a kaydediliyor mu?

4. **Training'de hesaplanan raw_r2 deÄŸerleri:**
   - Split 1: XGB raw_r2=?, LGB raw_r2=?, Cat raw_r2=?
   - Bu deÄŸerler HPO ile aynÄ± mÄ±?

5. **Ensemble aÄŸÄ±rlÄ±klarÄ±:**
   - HPO'da: final_weights = ?
   - Training'de: final_weights = ?
   - Bu aÄŸÄ±rlÄ±klar aynÄ± mÄ±?

6. **Prediction deÄŸerleri:**
   - HPO'da: ensemble_prediction = ?
   - Training'de: ensemble_prediction = ?
   - Bu deÄŸerler aynÄ± mÄ±?

---

## ğŸ’¡ Ã–NERÄ°LER

### KÄ±sa Vadede:
1. **Data source tutarlÄ±lÄ±ÄŸÄ±:** Training'de de cache'i bypass et
2. **historical_r2 kaydetme:** HPO'da hesaplanan `raw_r2` deÄŸerlerini best_params'a kaydet
3. **historical_r2 kullanma:** Training'de kaydedilen `raw_r2` deÄŸerlerini kullan

### Orta Vadede:
4. **Split doÄŸrulama:** HPO ve training'de aynÄ± split'leri kullandÄ±ÄŸÄ±nÄ± log ile doÄŸrula
5. **Ensemble aÄŸÄ±rlÄ±klarÄ± loglama:** HPO ve training'de ensemble aÄŸÄ±rlÄ±klarÄ±nÄ± logla ve karÅŸÄ±laÅŸtÄ±r
6. **Prediction karÅŸÄ±laÅŸtÄ±rma:** HPO ve training'de aynÄ± t iÃ§in prediction deÄŸerlerini karÅŸÄ±laÅŸtÄ±r

### Uzun Vadede:
7. **Deterministic ensemble:** HPO'da hesaplanan ensemble aÄŸÄ±rlÄ±klarÄ±nÄ± best_params'a kaydet ve training'de kullan
8. **Comprehensive logging:** TÃ¼m kritik deÄŸerleri (raw_r2, ensemble weights, predictions) logla
9. **Automated validation:** HPO sonrasÄ± otomatik olarak training ile karÅŸÄ±laÅŸtÄ±r ve farklarÄ± raporla

---

## ğŸ“Š SONUÃ‡

**Durum:** ğŸ”´ **Kritik farklÄ±lÄ±klar var**

**En Kritik Sorun:** `historical_r2` deÄŸerleri model eÄŸitimi sÄ±rasÄ±nda hesaplanÄ±yor ve bu deÄŸerler `smart_ensemble`'Ä±n aÄŸÄ±rlÄ±klarÄ±nÄ± etkiliyor. EÄŸer HPO ve training'de farklÄ± train data kullanÄ±lÄ±yorsa, farklÄ± `raw_r2` deÄŸerleri hesaplanÄ±r, bu da farklÄ± ensemble aÄŸÄ±rlÄ±klarÄ±na ve dolayÄ±sÄ±yla farklÄ± predictions'a yol aÃ§ar.

**Ã–ncelik:** 
1. Data source tutarlÄ±lÄ±ÄŸÄ±nÄ± saÄŸla
2. HPO'da hesaplanan `raw_r2` deÄŸerlerini best_params'a kaydet
3. Training'de kaydedilen `raw_r2` deÄŸerlerini kullan (model eÄŸitimi sÄ±rasÄ±nda deÄŸil, prediction sÄ±rasÄ±nda)

**Beklenen Ä°yileÅŸtirme:** Bu dÃ¼zeltmelerle Training DirHit'ler HPO DirHit'lere Ã§ok daha yakÄ±n olmalÄ±.

---

**Son GÃ¼ncelleme:** 2025-11-24 20:30

